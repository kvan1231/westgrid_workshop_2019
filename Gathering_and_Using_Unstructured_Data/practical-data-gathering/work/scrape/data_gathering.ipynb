{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "* We seek to model the outcome of a given playoff bracket based on historical performance data.\n",
    "\n",
    "* We do this via a tried and true method of monte carlo simulation. \n",
    "\n",
    "* We must first gather the data for this analysis to do this we will access a hockey statistics website\n",
    "\n",
    "* We require the historical game data for the year we'd like to model as well as some years previous.\n",
    "\n",
    "\n",
    "\n",
    "## Legal Disclaimer\n",
    "The analysis presented here is strictly for teaching purposes, \n",
    "\n",
    "The ToS of the website accessed is here:\n",
    "* https://www.sports-reference.com/termsofuse.html\n",
    "\n",
    "A statement about data requests here:\n",
    "* https://www.sports-reference.com/data_use.html\n",
    "\n",
    "And the associated robots.txt is here:\n",
    "* https://www.sports-reference.com/robots.txt\n",
    "\n",
    "As well as a guide to understanding these:\n",
    "* https://www.promptcloud.com/blog/how-to-read-and-respect-robots-file/\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import regex\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper to fetch historical game data and historical bracket data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_game_data(year):\n",
    "    contents = requests.get(f'https://www.hockey-reference.com/leagues/NHL_{year}_games.html')\n",
    "    soup = BeautifulSoup(contents.content)\n",
    "    \n",
    "    tables = soup.find_all('table')\n",
    "    \n",
    "    dataframes = {}\n",
    "    \n",
    "    for table in tables:\n",
    "        table_rows = table.find_all('tr')\n",
    "        data = {}\n",
    "        for row in table_rows[1:]:\n",
    "            cells = row.find_all('td') + row.find_all('th')\n",
    "            for cell in cells:\n",
    "                key = cell.get('data-stat')\n",
    "                if key not in data:\n",
    "                    data[key] = []\n",
    "                    data[key].append(cell.text)\n",
    "                else:\n",
    "                    data[key].append(cell.text)\n",
    "\n",
    "        df = pd.DataFrame(data=data)\n",
    "        \n",
    "        dataframes[table.find('caption').text] = df\n",
    "        \n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bracket_data(year):\n",
    "    playoff_pattern = '(?P<win>.*) over (?P<lose>.*)'\n",
    "    pp = regex.compile(playoff_pattern)\n",
    "    \n",
    "    contents = requests.get(f'https://www.hockey-reference.com/leagues/NHL_{year}.html')\n",
    "    soup = BeautifulSoup(contents.content)\n",
    "    \n",
    "    divisions = {\"Atlantic Division\":[],\n",
    "            \"Metropolitan Division\":[],\n",
    "            \"Central Division\":[],\n",
    "            \"Pacific Division\":[]}\n",
    "    \n",
    "    #key = None\n",
    "    \n",
    "    standings = [soup.find('table',id='standings_EAS'),soup.find('table',id='standings_WES')]\n",
    "\n",
    "    for table in standings:\n",
    "        rows = table.find_all('tr')\n",
    "        for row in rows[1:]:\n",
    "            if row.get('class')[0] == 'thead':\n",
    "                key = row.get_text().strip()\n",
    "            elif row.get('class')[0] == 'full_table':\n",
    "                team_name = [x.text for x in row.find_all('th') if x.get('data-stat') == 'team_name'][0]\n",
    "                pts = [x.text for x in row.find_all('td') if x.get('data-stat') == 'points'][0]\n",
    "                if '*' in team_name:\n",
    "                    divisions[key].append((int(pts),team_name.replace('*','')))\n",
    "                    \n",
    "                    \n",
    "    conferences= [('Atlantic Division','Metropolitan Division'),\n",
    "              ('Central Division', 'Pacific Division')]\n",
    "\n",
    "    results = {'first_round':[],\n",
    "               'second_round':[],\n",
    "               'conference_finals':[],\n",
    "               'final':[],\n",
    "               'winner':[]\n",
    "    }\n",
    "\n",
    "    for conference in conferences:\n",
    "\n",
    "        D1 = divisions[conference[0]][0:3]\n",
    "        D2 = divisions[conference[1]][0:3]\n",
    "\n",
    "        WC = divisions[conference[0]][3:] + divisions[conference[1]][3:]\n",
    "\n",
    "\n",
    "        if len(set([x[0] for x in WC])) == 1 or len(set([x[0] for x in [D1[0]]+[D2[0]]])) == 1:\n",
    "\n",
    "            print('SEEDING TIE!\\n')\n",
    "            print(f'1    {D1[0][1]} vs {WC[0][1]} AND {D2[0][1]} vs {WC[1][1]}')\n",
    "            print('OR')\n",
    "            print(f'2    {D1[0][1]} vs {WC[1][1]} AND {D2[0][1]} vs {WC[0][1]}')\n",
    "\n",
    "            \n",
    "            display(HTML(f'<a href=\"https://en.wikipedia.org/wiki/{year}_Stanley_Cup_playoffs#Playoff_bracket\">Wikipedia Bracket</a>'))\n",
    "            \n",
    "            inp = input('Please verify the correct seed (1 or 2):')  \n",
    "\n",
    "            if inp == '1':\n",
    "                D1.insert(1,WC[0])\n",
    "                D2.insert(1,WC[1])\n",
    "            elif inp == '2':\n",
    "                D1.insert(1,WC[1])\n",
    "                D2.insert(1,WC[0])\n",
    "            else:\n",
    "                raise Exception('Incorrect Input Selected!')\n",
    "\n",
    "        else:   \n",
    "            ordered = list(sorted(WC,reverse=True))\n",
    "\n",
    "            if D1[0][0] > D2[0][0]:\n",
    "                D1.insert(1,ordered[-1])\n",
    "                D2.insert(1,ordered[0])\n",
    "            else:\n",
    "                D2.insert(1,ordered[-1])\n",
    "                D1.insert(1,ordered[0])\n",
    "\n",
    "        results['first_round'] = results['first_round'] + D1 + D2\n",
    "\n",
    "    results['first_round'] = [x[1] for x in results['first_round']]\n",
    "        \n",
    "    # Get remaining rounds and reorder accordingly  \n",
    "    \n",
    "    poff_table = soup.find('table',id='all_playoffs')\n",
    "    \n",
    "    poff_rows = poff_table.find_all('tr')\n",
    "    \n",
    "    for row in poff_rows:\n",
    "        cells = [c.text for c in row.find_all('td')]\n",
    "        if 'First Round' in cells:\n",
    "            key = None\n",
    "        if 'Second Round' in cells:\n",
    "            key = 'second_round'\n",
    "        elif 'Conference Finals' in cells:\n",
    "            key = 'conference_finals'\n",
    "        elif 'Final' in cells:\n",
    "            key = 'final'\n",
    "\n",
    "        if key:\n",
    "            for cell in cells:\n",
    "                m = pp.match(cell)\n",
    "                if m:\n",
    "                    d = m.capturesdict()\n",
    "                    results[key].append(d['win'][0])\n",
    "                    results[key].append(d['lose'][0])\n",
    "\n",
    "                    if key == 'final':\n",
    "                        results['winner'].append(d['win'][0])\n",
    "\n",
    "    \n",
    "    \n",
    "    # Reorder for compatibility\n",
    "    \n",
    "    keys = ['first_round','second_round','conference_finals','final']\n",
    "    \n",
    "    for i in range(1,len(keys)):\n",
    "        temp = []\n",
    "        for team in results[keys[i-1]]:\n",
    "            if team in results[keys[i]]:\n",
    "                temp.append(team)\n",
    "        \n",
    "        results[keys[i]] = temp         \n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(year):\n",
    "    games = get_game_data(year)\n",
    "    bracket = get_bracket_data(year)\n",
    "    \n",
    "    directory = os.path.join('data',str(year))\n",
    "    \n",
    "    if not os.path.isdir(directory):\n",
    "        os.mkdir(directory)\n",
    "    \n",
    "    with open(os.path.join(directory,'bracket.json'),'w') as f:\n",
    "        json.dump(bracket,f)\n",
    "        \n",
    "    games['Regular Season Table'].to_csv(os.path.join(directory,'regular.csv'),index=False)\n",
    "    games['Playoffs Table'].to_csv(os.path.join(directory,'playoffs.csv'),index=False)\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMEOUT = 10 #s\n",
    "\n",
    "for year in range(2014,2020):\n",
    "    print(f'Fetching {year}')\n",
    "    save_data(year)\n",
    "    time.sleep(TIMEOUT) # timeout to prevent overloading the servers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
