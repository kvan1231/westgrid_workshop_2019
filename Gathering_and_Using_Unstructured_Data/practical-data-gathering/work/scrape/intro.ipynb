{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "* Many sources of information on the internet are presented for purely human consumption on a web page.\n",
    "* This can either be intentional or unintentional.\n",
    "* Even though websites appear to be highly unstructured, the underlying language HTML cannot be.\n",
    "    * We can take advantage of this fact to generate structured datasets from the \"unstructured\" website\n",
    "    \n",
    "## Legal Disclaimer\n",
    "* The legality of webscraping is a subject for debate and varies on a case by case basis, we need to be cognizant of this when engaging in such practices:\n",
    "    * http://www.prowebscraper.com/blog/six-compelling-facts-about-legality-of-web-scraping/\n",
    "    \n",
    "* Be sure to consult the ToS to see if there are violations by scraping the website.\n",
    "    \n",
    "* If it's allowed, a general rule of thumb is to not be disruptive/damaging to the service freely providing the information, i.e. if you decide to scrape a website don't send more requests than is reasonable for a human browsing the website.\n",
    "    \n",
    "## Overview\n",
    "\n",
    "* We use both the requests library (seen previously) and a library called \"Beautiful Soup\" used commonly for webscraping in python.\n",
    "\n",
    "* We will introduce the basic concepts on a \"scraping sandbox\" that is provided by scraping web service:  http://toscrape.com/\n",
    "\n",
    "* More specifically we will focus on the \"book store example\" http://books.toscrape.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Madeup Bookstore\n",
    "\n",
    "* Suppose we want to create an algorithm for selecting the next book we want to buy and read.\n",
    "    * lets keep it simple like stars per dollar!\n",
    "* There's no API from this bookstore so we'd either need to go through and manually enter data into a spreadsheet!\n",
    "* Alternatively we can have the computer take care of this tedious work, we just need to be clever about it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = requests.get('http://books.toscrape.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(content.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sense of the data\n",
    "\n",
    "* This is clearly a mess so how do we make sense of it??\n",
    "* The answer is beautiful soup!\n",
    "    * HTML parsing library that's pretty easy to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(content.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing the elements we care about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pods = soup.find_all('article',class_=\"product_pod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pods[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay now we can find the title\n",
    "pods[0].find('h3').find('a').get('title')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay now we can find ratings\n",
    "pods[0].find('p',class_='star-rating').get('class')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bingo we got the price!\n",
    "pods[0].find('p',class_=\"price_color\").text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting more than one Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_stars(stars):\n",
    "    \n",
    "    s = stars.lower().strip()\n",
    "    \n",
    "    if s == 'one':\n",
    "        return 1\n",
    "    elif s == 'two':\n",
    "        return 2\n",
    "    elif s == 'three':\n",
    "        return 3\n",
    "    elif s == 'four':\n",
    "        return 4\n",
    "    elif s == 'five':\n",
    "        return 5\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pods(pods):\n",
    "\n",
    "    data = {'titles':[],\n",
    "            'stars':[],\n",
    "            'price':[]}\n",
    "\n",
    "    for pod in pods:\n",
    "\n",
    "        title = pod.find('h3').find('a').get('title')\n",
    "\n",
    "        data['titles'].append(title)\n",
    "\n",
    "        stars = switch_stars(pod.find('p',class_='star-rating').get('class')[1])\n",
    "\n",
    "        data['stars'].append(stars)\n",
    "\n",
    "        price = float(pod.find('p',class_=\"price_color\").text[1:])\n",
    "\n",
    "        data['price'].append(price)\n",
    "        \n",
    "    df = pd.DataFrame(data=data)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parse_pods(pods)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding more pages\n",
    "* We're going to a pretty sloppy hack to grab the next pages\n",
    "* Can you see how the url changes as we switch pages?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    content = requests.get(f'http://books.toscrape.com/catalogue/page-{i}.html')\n",
    "    soup = BeautifulSoup(content.content)\n",
    "    pods = soup.find_all('article',class_=\"product_pod\")\n",
    "    \n",
    "    dataframes.append(parse_pods(pods))\n",
    "\n",
    "    time.sleep(3) # time out so we're not jerks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dataframes,ignore_index=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price_per_star'] = df['price']/df['stars']\n",
    "df.sort_values(by = 'price_per_star',ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges\n",
    "\n",
    "* Can you grab the authors? \n",
    "* Can you grab the genres? \n",
    "* Can you get the next pages from the hyperlinks?\n",
    "* Can you get the \"ISBN\"?\n",
    "* Can you get the description?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
